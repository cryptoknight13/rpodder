<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rakesh Podder - Researcher in Cybersecurity, AI & ML</title>
  <link rel="stylesheet" href="styles.css">
  <!-- Font Awesome CDN for social media icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Lobster&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Tangerine:bold,bolditalic|Inconsolata:italic|Droid+Sans" rel="stylesheet">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@400..700&family=Poppins:wght@400;500;600&display=swap" rel="stylesheet">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@400..700&family=Great+Vibes&family=Poppins:wght@400;500;600&display=swap" rel="stylesheet">  
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@400..700&family=Great+Vibes&family=Pirata+One&family=Poppins:wght@400;500;600&display=swap" rel="stylesheet">  
  <link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@400..700&family=Great+Vibes&family=Oleo+Script:wght@400;700&family=Pirata+One&family=Poppins:wght@400;500;600&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Chokokutai&family=Dancing+Script:wght@400..700&family=Great+Vibes&family=Oleo+Script:wght@400;700&family=Pirata+One&family=Poppins:wght@400;500;600&family=Rochester&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Chokokutai&family=Dancing+Script:wght@400..700&family=Great+Vibes&family=Oleo+Script:wght@400;700&family=Pirata+One&family=Playwrite+GB+S:ital,wght@0,100..400;1,100..400&family=Poppins:wght@400;500;600&family=Rochester&display=swap" rel="stylesheet">
</head>
<body>
  <header>
    <h1>Rakesh Podder</h1>
    <p>Researcher in Cybersecurity, Firmware Security, AI, and Machine Learning. <a href="https://scholar.google.com/citations?user=LznkBwUAAAAJ&hl=en" target="_blank" class="custom-link">[Google Scholar]</a></p>
  </header>
  
  <!-- Full-width navigation bar below header -->
  <nav class="full-width-nav">
    <ul class="tabs">
      <li><a href="index.html">Home</a></li>
      <li><a href="education.html" >Education</a></li>
      <li><a href="research.html" class="active">Research</a></li>
      <li><a href="publications.html">Publications</a></li>
      <li><a href="events.html" >Events</a></li>
      <li><a href="achievement.html">Achievements</a></li>
      <li><a href="contact.html" >Contact</a></li>
    </ul>
  </nav>

  <!-- Navigation Buttons -->
  <nav class="research-nav">
    <a href="ai-planning.html" class="btn">Previous</a>
    <a href="formal-methods.html" class="btn">Next</a>
  </nav>

  <section>
    <div class="research-detail">
        <h2>Adversarial attacks on CNN Model</h2>
        <p>We conduct a systematic evaluation
            of various white-box adversarial attacks, where the attacker
            has complete visibility into the modelâ€™s architecture, parame-
            ters, and training data, on generic neural network models for
            images. We use a curated set of images such as the MNIST,
            CIFAR-10, CIFAR-100, and Fashion MNIST datasets
            processed by a Convolutional Neural Network (CNN). The
            datasets take into account the variety and complexity required
            to challenge the CNNs under test. We identify the intrinsic
            vulnerabilities of CNNs when exposed to white-box attacks
            such as Fast Gradient Sign Method (FGSM), Basic Iter-
            ative Method (BIM), Jacobian-based Saliency Map
            Attack (JSMA), Carlini & Wagner (C&W), Projected
            Gradient Descent (PGD), and DeepFool.</p>
        
        <!-- Image Gallery -->
        <div class="research-gallery">
            <img src="images/ef.png" alt="Evaluation Framework">
            <img src="images/tabII.png" alt="Table">
            <img src="images/attack1.png" alt="Attack 1">
            <img src="images/attack2.png" alt="attack2">
            <img src="images/comparison-image.png" alt="Comparison">
        </div>
        <p>Autonomous vehicle navigation and healthcare diagnostics are among the many fields where the reliability and security of machine learning models for image data are critical. We conduct a comprehensive investigation into the susceptibility of Convolutional Neural Networks (CNNs), which are widely used for image data, to white-box adversarial attacks. We investigate the effects of various sophisticated attacks---Fast Gradient Sign Method, Basic Iterative Method, Jacobian-based Saliency Map Attack, Carlini \& Wagner, Projected Gradient Descent, and DeepFool---on CNN performance metrics, (e.g., loss, accuracy), the differential efficacy of adversarial techniques in increasing error rates, the relationship between perceived image quality metrics (e.g., ERGAS, PSNR, SSIM, and SAM) and classification performance, and the comparative effectiveness of iterative versus single-step attacks. Using the MNIST, CIFAR-10, CIFAR-100, and Fashion\_MNIST datasets, we explore the effect of different attacks on the CNNs performance metrics by varying the hyperparameters of CNNs. Our study provides insights into the robustness of CNNs against adversarial threats, pinpoints vulnerabilities, and underscores the urgent need for developing robust defense mechanisms to protect CNNs and ensuring their trustworthy deployment in real-world scenarios.</p>
    </div>
  </section>

  <!-- Navigation Buttons at the Bottom as well -->
  <nav class="research-nav">
    <a href="ai-planning.html" class="btn">Previous</a>
    <a href="formal-methods.html" class="btn">Next</a>
  </nav>
</section>
<footer>
    <p>&copy; 2024 Rakesh Podder</p>
</footer>
</body>
</html>
