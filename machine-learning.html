<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Rakesh Podder - Education</title>
  <link rel="stylesheet" href="/rpodder/Style/ml.css"/>
  <script src="menu.js" defer></script>
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"/>
</head>

<body>

<!-- Top Menu Bar -->
<div class="top-bar">
  <div class="left-placeholder"></div>
  <div class="right-menu">
    <div class="menu-toggle" id="menu-toggle">
      <i class="fa fa-bars"></i>
    </div>
    <nav class="full-width-nav" id="full-width-nav">
      <ul class="tabs">
        <li><a href="index.html">Home</a></li>
        <li><a href="education.html" >Education</a></li>
        <li><a href="research.html" class="active">Research</a></li>
        <li><a href="publications.html">Publications</a></li>
        <li><a href="events.html" >Events</a></li>
        <li><a href="achievement.html">Achievements</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
    </nav>
  </div>
</div>

<!-- Name Section -->
<section class="name-section">
  <h1 class="name-with-line">Adversarial Attacks on CNN Models</h1>
</section>

  <!-- Navigation Buttons at the Bottom as well -->
  <nav class="research-nav">
    <a href="ai-planning.html" class="btn">Previous</a>
    <a href="formal-methods.html" class="btn">Next</a>
  </nav>
   
<!-- Research Section -->
<section id="research">

  <!-- Overview -->
  <h3 class="research-section-title">Overview</h3>
  <p>
    We conduct a systematic evaluation of various white-box adversarial attacks, where the attacker has complete visibility into the model’s architecture, parameters, and training data, on generic neural network models for images.
    We use datasets such as MNIST, CIFAR-10, CIFAR-100, and Fashion MNIST processed by a Convolutional Neural Network (CNN).
    We identify the intrinsic vulnerabilities of CNNs when exposed to white-box attacks such as FGSM, BIM, JSMA, C&W, PGD, and DeepFool.
  </p>

  <!-- Objectives -->
  <h3 class="research-section-title">Research Objectives</h3>
  <ul class="research-objectives">
    <li>Evaluate CNN robustness against advanced white-box adversarial attacks.</li>
    <li>Compare the impact of single-step vs iterative attacks.</li>
    <li>Analyze correlation between image quality metrics and classification accuracy.</li>
    <li>Provide insights for developing robust CNN defense mechanisms.</li>
  </ul>

  <!-- Methods -->
  <h3 class="research-section-title">Methods</h3>
  <p>
    We investigate the effects of various sophisticated attacks — FGSM, BIM, JSMA, C&W, PGD, and DeepFool — on CNN performance metrics such as loss and accuracy.
    We analyze multiple image datasets (MNIST, CIFAR-10, CIFAR-100, Fashion-MNIST) to provide a comprehensive comparison.
    We also explore how image quality metrics (ERGAS, PSNR, SSIM, SAM) correlate with classification performance.
  </p>

  <!-- Image Gallery -->
  <h3 class="research-section-title">Results & Visualizations</h3>
  <div class="research-gallery">
    <img src="images/ef.png" alt="Evaluation Framework">
    <img src="images/tabII.png" alt="Evaluation Table">
    <img src="images/attack1.png" alt="Attack Example 1">
    <img src="images/attack2.png" alt="Attack Example 2">
    <img src="images/comparison-image.png" alt="Attack Comparison">
  </div>

  <!-- Impact -->
  <h3 class="research-section-title">Impact</h3>
  <p>
    Our study highlights significant vulnerabilities in CNN models when subjected to adversarial attacks.
    It emphasizes the need for robust defense strategies to ensure reliable deployment of CNNs in real-world critical domains such as autonomous vehicles and healthcare diagnostics.
    We provide a foundation for future work on adaptive CNN defense mechanisms and explainability-driven adversarial robustness.
  </p>

</section>
  </section>
  

  <!-- Navigation Buttons at the Bottom as well -->
  <nav class="research-nav">
    <a href="ai-planning.html" class="btn">Previous</a>
    <a href="formal-methods.html" class="btn">Next</a>
  </nav>

<footer>
    <p>&copy; 2025 Rakesh Podder</p>
</footer>
</body>
</html>
